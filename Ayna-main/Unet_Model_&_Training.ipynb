{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "UNET MODEL IMPLEMENTATION\n"
      ],
      "metadata": {
        "id": "5t1qRVcxmwL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch ##using Pytorch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Feature-wise Linear Modulation (FiLM) Layer\n",
        "class FiLM(nn.Module):\n",
        "    def __init__(self, cond_dim, num_features):\n",
        "        super().__init__()\n",
        "        self.film = nn.Linear(cond_dim, num_features * 2)\n",
        "\n",
        "    def forward(self, x, cond_vec):\n",
        "        gamma_beta = self.film(cond_vec)\n",
        "        gamma, beta = gamma_beta.chunk(2, dim=1)\n",
        "        gamma = gamma.view(-1, x.size(1), 1, 1)\n",
        "        beta = beta.view(-1, x.size(1), 1, 1)\n",
        "        return gamma, beta\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, cond_dim=None, use_film=True):\n",
        "        super().__init__()\n",
        "        self.use_film = use_film and (cond_dim is not None)\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
        "        self.norm1 = nn.GroupNorm(8, out_ch)\n",
        "        self.norm2 = nn.GroupNorm(8, out_ch)\n",
        "        self.film1 = FiLM(cond_dim, out_ch) if self.use_film else None\n",
        "        self.film2 = FiLM(cond_dim, out_ch) if self.use_film else None\n",
        "        self.act = nn.SiLU()\n",
        "\n",
        "    def forward(self, x, cond_vec=None):\n",
        "        x = self.conv1(x)\n",
        "        x = self.norm1(x)\n",
        "        if self.use_film and cond_vec is not None:\n",
        "            g, b = self.film1(x, cond_vec)\n",
        "            x = g * x + b\n",
        "        x = self.act(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.norm2(x)\n",
        "        if self.use_film and cond_vec is not None:\n",
        "            g, b = self.film2(x, cond_vec)\n",
        "            x = g * x + b\n",
        "        return self.act(x)\n",
        "\n",
        "# Full UNet with various conditions\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_ch=4, out_ch=4, cond_dim=128):\n",
        "        super().__init__()\n",
        "        self.enc1 = ConvBlock(in_ch, 64, cond_dim)\n",
        "        self.enc2 = ConvBlock(64, 128, cond_dim)\n",
        "        self.enc3 = ConvBlock(128, 256, cond_dim)\n",
        "        self.enc4 = ConvBlock(256, 512, cond_dim)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "        self.mid = ConvBlock(512, 1024, cond_dim)\n",
        "\n",
        "        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
        "        self.dec4 = ConvBlock(1024, 512, cond_dim)\n",
        "\n",
        "        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
        "        self.dec3 = ConvBlock(512, 256, cond_dim)\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.dec2 = ConvBlock(256, 128, cond_dim)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.dec1 = ConvBlock(128, 64, cond_dim)\n",
        "\n",
        "        self.out_conv = nn.Conv2d(64, out_ch, kernel_size=1)\n",
        "\n",
        "        # To embed color information ((RGB)\n",
        "        self.cond_emb = nn.Linear(9, cond_dim)  # Assuming 9-dim input condition\n",
        "\n",
        "    def forward(self, x, color_idx=None, color_rgb=None):\n",
        "        # Using RGB color\n",
        "        if color_idx is not None:\n",
        "            cond_input = color_idx\n",
        "        else:\n",
        "            cond_input = color_rgb\n",
        "        cond_vec = self.cond_emb(cond_input)\n",
        "\n",
        "        # Encoding path\n",
        "        x1 = self.enc1(x, cond_vec)\n",
        "        x2 = self.enc2(self.pool(x1), cond_vec)\n",
        "        x3 = self.enc3(self.pool(x2), cond_vec)\n",
        "        x4 = self.enc4(self.pool(x3), cond_vec)\n",
        "\n",
        "        x_mid = self.mid(self.pool(x4), cond_vec)\n",
        "\n",
        "        # Decoding path\n",
        "        x = self.up4(x_mid)\n",
        "        x = self.dec4(torch.cat([x4, x], dim=1), cond_vec)\n",
        "\n",
        "        x = self.up3(x)\n",
        "        x = self.dec3(torch.cat([x3, x], dim=1), cond_vec)\n",
        "\n",
        "        x = self.up2(x)\n",
        "        x = self.dec2(torch.cat([x2, x], dim=1), cond_vec)\n",
        "\n",
        "        x = self.up1(x)\n",
        "        x = self.dec1(torch.cat([x1, x], dim=1), cond_vec)\n",
        "\n",
        "        return self.out_conv(x)\n"
      ],
      "metadata": {
        "id": "PKkBCORpm0Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING SCRIPT"
      ],
      "metadata": {
        "id": "p4AGDfYjm5r4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_val = float('inf')\n",
        "save_path = f\"/content/cond_unet_{COND_METHOD}.pt\"\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    running = {\"loss\": 0.0, \"mse\": 0.0, \"l1\": 0.0}\n",
        "\n",
        "    for batch in train_loader:\n",
        "        img = batch[\"inp\"].to(device)\n",
        "        tgt = batch[\"target\"].to(device)\n",
        "        color_idx = batch[\"color_idx\"].to(device)\n",
        "        color_rgb = batch[\"color_rgb\"].to(device)\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
        "            pred = model(img, color_idx, color_rgb)\n",
        "            loss = F.l1_loss(pred, tgt) * 0.7 + F.mse_loss(pred, tgt) * 0.3\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "\n",
        "        m = compute_metrics(pred.detach(), tgt)\n",
        "        running[\"loss\"] += loss.item()\n",
        "        running[\"mse\"]  += m[\"mse\"]\n",
        "        running[\"l1\"]   += m[\"l1\"]\n",
        "\n",
        "    # Averaging metrics per epoch\n",
        "    n_batches = len(train_loader)\n",
        "    train_log = {k: v / n_batches for k, v in running.items()}\n"
      ],
      "metadata": {
        "id": "80ovMpEem7ao"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}